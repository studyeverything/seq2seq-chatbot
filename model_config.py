# model seq2seq config
emb_dim = 1024
batch_size = 32

# training config
n_epoch = 50

# data processing tokens express
UNK = 'unk'  # not in dictionary, unknown
VOCAB_SIZE = 6000
